{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the LSTM implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my LSTM analysis."
      ],
      "metadata": {
        "id": "FpBX9g4600Dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8lCByp9dFa",
        "outputId": "4e2c2765-a2c2-4d16-a119-6656d494be5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB1g1ok5-QKw",
        "outputId": "a9080551-8bfc-404c-ab3c-62bb800159a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 32, 4975)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjUzGyL7_Axu",
        "outputId": "33581d20-19c0-4ae1-f4a8-9a8e71dabdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFPmhtp7aiWq",
        "outputId": "cd5125e9-daa4-4d2f-daa4-aa81192f6334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjQMu7gFfP4l",
        "outputId": "7e5bcbb2-d34d-4b11-cd4e-f0cf6a26a2cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 64, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ue33eB8Yf3SD"
      },
      "outputs": [],
      "source": [
        "eeg_labels = eo_eeg_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVj56z0sfEWf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uu4_RU-iPuh",
        "outputId": "05b1fd13-73d0-45bd-f3ba-7b54300d4ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD patient: 3780\n",
            "Number of Healthy patient: 564\n"
          ]
        }
      ],
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD patient: {mdd_count}\")\n",
        "print(f\"Number of Healthy patient: {healthy_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyjPRqmaPN8"
      },
      "source": [
        "### **Converting the labels to binary**\n",
        "1 -> MDD\n",
        "\n",
        "0 -> HEALTHY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU3J9Y7Yq5bZ",
        "outputId": "7548cf3f-a110-4c30-f361-7e0bcbd8b560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered ec_eeg_labels: 4248\n",
            "Length of filtered eeg_data: 4248\n",
            "4248\n",
            "354\n",
            "94\n",
            "(1128, 64, 4975)\n"
          ]
        }
      ],
      "source": [
        "ll = ec_eeg_labels\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "ec_eeg_labels = [sample for i, sample in enumerate(ec_eeg_labels) if i not in indices_to_remove]\n",
        "eeg_data = [data for i, data in enumerate(eeg_data) if i not in indices_to_remove]\n",
        "print(\"Length of filtered ec_eeg_labels:\", len(ec_eeg_labels))\n",
        "print(\"Length of filtered eeg_data:\", len(eeg_data))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = ec_eeg_labels\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 47\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(ec_eeg_labels):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data[i])\n",
        "    y_train.append(eeg_labels[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2FuAEUFf-Cf",
        "outputId": "a55ddfdc-474d-4126-ef34-c5fc26ed678e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Test Loss: 0.6380736231803894, Test Accuracy: 0.830376923084259, Precision: 0.8860971331596375, Recall: 0.861563503742218\n",
            "29/29 [==============================] - 1s 14ms/step\n",
            "F1 Score: 0.8736581337737408\n",
            "Confusion Matrix:\n",
            "[[220  68]\n",
            " [ 85 529]]\n",
            "Training Results - Loss: 0.6380736231803894, Accuracy: 0.830376923084259, Precision: 0.8860971331596375, Recall: 0.861563503742218, F1 Score: 0.8736581337737408\n",
            "Test Loss: 2.0508487224578857, Test Accuracy: 0.5353982448577881, Precision: 0.7094017267227173, Recall: 0.5389610528945923\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.6125461254612546\n",
            "Confusion Matrix:\n",
            "[[38 34]\n",
            " [71 83]]\n",
            "Validation Results - Loss: 2.0508487224578857, Accuracy: 0.5353982448577881, Precision: 0.7094017267227173, Recall: 0.5389610528945923, F1 Score: 0.6125461254612546\n",
            "\n",
            "Fold 2:\n",
            "Test Loss: 0.9261776804924011, Test Accuracy: 0.7949002385139465, Precision: 0.8950276374816895, Recall: 0.791530966758728\n",
            "29/29 [==============================] - 0s 14ms/step\n",
            "F1 Score: 0.8401037165082109\n",
            "Confusion Matrix:\n",
            "[[231  57]\n",
            " [128 486]]\n",
            "Training Results - Loss: 0.9261776804924011, Accuracy: 0.7949002385139465, Precision: 0.8950276374816895, Recall: 0.791530966758728, F1 Score: 0.8401037165082109\n",
            "Test Loss: 1.7752758264541626, Test Accuracy: 0.6681416034698486, Precision: 0.8062015771865845, Recall: 0.6753246784210205\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.7349823321554771\n",
            "Confusion Matrix:\n",
            "[[ 47  25]\n",
            " [ 50 104]]\n",
            "Validation Results - Loss: 1.7752758264541626, Accuracy: 0.6681416034698486, Precision: 0.8062015771865845, Recall: 0.6753246784210205, F1 Score: 0.7349823321554771\n",
            "\n",
            "Fold 3:\n",
            "Test Loss: 1.1350654363632202, Test Accuracy: 0.7682926654815674, Precision: 0.8886756300926208, Recall: 0.7540716528892517\n",
            "29/29 [==============================] - 0s 14ms/step\n",
            "F1 Score: 0.8158590308370044\n",
            "Confusion Matrix:\n",
            "[[230  58]\n",
            " [151 463]]\n",
            "Training Results - Loss: 1.1350654363632202, Accuracy: 0.7682926654815674, Precision: 0.8886756300926208, Recall: 0.7540716528892517, F1 Score: 0.8158590308370044\n",
            "Test Loss: 1.3914052248001099, Test Accuracy: 0.721238911151886, Precision: 0.8273381590843201, Recall: 0.7467532753944397\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.7849829351535835\n",
            "Confusion Matrix:\n",
            "[[ 48  24]\n",
            " [ 39 115]]\n",
            "Validation Results - Loss: 1.3914052248001099, Accuracy: 0.721238911151886, Precision: 0.8273381590843201, Recall: 0.7467532753944397, F1 Score: 0.7849829351535835\n",
            "\n",
            "Fold 4:\n",
            "Test Loss: 1.1438724994659424, Test Accuracy: 0.7707641124725342, Precision: 0.8366336822509766, Recall: 0.8243902325630188\n",
            "29/29 [==============================] - 0s 14ms/step\n",
            "F1 Score: 0.8304668304668305\n",
            "Confusion Matrix:\n",
            "[[189  99]\n",
            " [108 507]]\n",
            "Training Results - Loss: 1.1438724994659424, Accuracy: 0.7707641124725342, Precision: 0.8366336822509766, Recall: 0.8243902325630188, F1 Score: 0.8304668304668305\n",
            "Test Loss: 1.4410032033920288, Test Accuracy: 0.7333333492279053, Precision: 0.8120805621147156, Recall: 0.7908496856689453\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.8013245033112583\n",
            "Confusion Matrix:\n",
            "[[ 44  28]\n",
            " [ 32 121]]\n",
            "Validation Results - Loss: 1.4410032033920288, Accuracy: 0.7333333492279053, Precision: 0.8120805621147156, Recall: 0.7908496856689453, F1 Score: 0.8013245033112583\n",
            "\n",
            "Fold 5:\n",
            "Test Loss: 1.7898222208023071, Test Accuracy: 0.7475082874298096, Precision: 0.9143468737602234, Recall: 0.6943089365959167\n",
            "29/29 [==============================] - 0s 14ms/step\n",
            "F1 Score: 0.789279112754159\n",
            "Confusion Matrix:\n",
            "[[248  40]\n",
            " [188 427]]\n",
            "Training Results - Loss: 1.7898222208023071, Accuracy: 0.7475082874298096, Precision: 0.9143468737602234, Recall: 0.6943089365959167, F1 Score: 0.789279112754159\n",
            "Test Loss: 2.5775933265686035, Test Accuracy: 0.6622222065925598, Precision: 0.8666666746139526, Recall: 0.5947712659835815\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.7054263565891472\n",
            "Confusion Matrix:\n",
            "[[58 14]\n",
            " [62 91]]\n",
            "Validation Results - Loss: 2.5775933265686035, Accuracy: 0.6622222065925598, Precision: 0.8666666746139526, Recall: 0.5947712659835815, F1 Score: 0.7054263565891472\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, BatchNormalization, Dense\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(64, 4975)):\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def build_model(self, optimizer='adam', learning_rate=0.001):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units=64, input_shape=self.input_shape, return_sequences=True))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(LSTM(units=64, return_sequences=True))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(LSTM(units=32))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(units=32, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "        if optimizer == 'adam':\n",
        "            optimizer = Adam(learning_rate=learning_rate)\n",
        "        elif optimizer == 'sgd':\n",
        "            optimizer = SGD(learning_rate=learning_rate)\n",
        "        elif optimizer == 'rmsprop':\n",
        "            optimizer = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, best_params):\n",
        "        # Extract the best hyperparameters\n",
        "        epochs = best_params['epochs']\n",
        "        batch_size = best_params['batch_size']\n",
        "        optimizer = best_params['optimizer']\n",
        "        learning_rate = best_params['learning_rate']\n",
        "\n",
        "        # Build the model with the best hyperparameters\n",
        "        model = self.build_model(optimizer=optimizer, learning_rate=learning_rate)\n",
        "\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=1)\n",
        "        return model, history\n",
        "\n",
        "    def evaluate(self, X_test, y_test, model):\n",
        "        loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f'Test Loss: {loss}, Test Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        print(f'F1 Score: {f1}')\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "        print('Confusion Matrix:')\n",
        "        print(cm)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X, model):\n",
        "        return model.predict(X)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "def hyperparameter_tuning(X_train, y_train):\n",
        "    eeg_classifier = EEGClassifier()\n",
        "\n",
        "    model = KerasClassifier(model=eeg_classifier.build_model, verbose=0)\n",
        "\n",
        "    param_grid = {\n",
        "        'epochs': [50, 100],\n",
        "        'batch_size': [32, 64],\n",
        "        'optimizer': ['adam', 'rmsprop'],\n",
        "        'learning_rate': [0.01, 0.001, 0.005, 0.0001]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1)\n",
        "    grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "    best_params = grid_result.best_params_\n",
        "    best_model = grid_result.best_estimator_\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best Model: {best_model}\")\n",
        "\n",
        "    return best_params, best_model\n",
        "\n",
        "def main():\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    # Dummy data creation for example\n",
        "    X = np.random.rand(100, 64, 4975)  # 100 samples, 64 time steps, 4975 features\n",
        "    y = np.random.randint(2, size=100)  # Binary targets\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    all_metrics = {\n",
        "        'loss': [],\n",
        "        'accuracy': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'f1_score': []\n",
        "    }\n",
        "    all_confusion_matrices = []\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X, y), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "        best_params, _ = hyperparameter_tuning(X_train_fold, y_train_fold)\n",
        "\n",
        "        # Train with best parameters\n",
        "        model, history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold, best_params)\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold, model)\n",
        "        for key in all_metrics.keys():\n",
        "            all_metrics[key].append(val_metrics[key])\n",
        "        all_confusion_matrices.append(val_metrics['confusion_matrix'])\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_metrics = {key: np.mean(all_metrics[key]) for key in all_metrics.keys()}\n",
        "    print(f'Average Validation Results - Loss: {avg_metrics[\"loss\"]}, Accuracy: {avg_metrics[\"accuracy\"]}, '\n",
        "          f'Precision: {avg_metrics[\"precision\"]}, Recall: {avg_metrics[\"recall\"]}, '\n",
        "          f'F1 Score: {avg_metrics[\"f1_score\"]}')\n",
        "\n",
        "    # Summarize confusion matrix\n",
        "    summed_confusion_matrix = np.sum(all_confusion_matrices, axis=0)\n",
        "    print('Summed Confusion Matrix:')\n",
        "    print(summed_confusion_matrix)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}