{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the SVM implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/jayavardhanravi/EEG-Data-predection/blob/master/mypart1.py. This resource provided invaluable support for my SVM analysis."
      ],
      "metadata": {
        "id": "ei4N7PVjTIrP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8lCByp9dFa",
        "outputId": "4afec209-be8e-4939-969d-95d1ce51114b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB1g1ok5-QKw",
        "outputId": "92999143-6502-41cd-b4bc-952a647f9e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 32, 4975)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjUzGyL7_Axu",
        "outputId": "48876cfd-cd57-4900-f349-4514d12900b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FP49u4sF0D0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811daf9a-271e-4b2b-f170-0acd442a9718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)\n",
        "\n",
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape\n",
        "\n",
        "eeg_labels = ec_eeg_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6o2e6442_rix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf82c05-7194-4a54-f6c8-0e73861f2daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD participants: 3780\n",
            "Number of Healthy participants: 564\n"
          ]
        }
      ],
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD participants: {mdd_count}\")\n",
        "print(f\"Number of Healthy participants: {healthy_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMj3gbuquMBf"
      },
      "source": [
        "#Extracting data for female participants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AO_353PuuLbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459efb8e-47dc-4ac6-9ce0-432de312bc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1932, 64, 4975) (1932, 2)\n"
          ]
        }
      ],
      "source": [
        "df_participants = pd.read_pickle('/content/drive/MyDrive/TD-BRAIN/TDBRAIN_participants_V2_data/df_participants.pkl')\n",
        "female_count = 0\n",
        "\n",
        "eeg_data_female = []\n",
        "eeg_label_female = []\n",
        "\n",
        "for i, labels in enumerate(eeg_labels):\n",
        "     sample_id = labels[0]\n",
        "     index = df_participants.loc[df_participants['participants_ID'] == sample_id].index\n",
        "     if [value for value in df_participants.loc[index, 'gender']][0] == 1:\n",
        "       eeg_data_female.append(eeg_data[i])\n",
        "       eeg_label_female.append(eeg_labels[i])\n",
        "\n",
        "eeg_data_female = np.array(eeg_data_female)\n",
        "eeg_label_female = np.array(eeg_label_female)\n",
        "\n",
        "print(eeg_data_female.shape, eeg_label_female.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o_V9agNEFFYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1557c9e-f930-4b74-e3e2-355f5b05121f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD female participants: 1740\n",
            "Number of Healthy female participants: 192\n"
          ]
        }
      ],
      "source": [
        "healthy_count_female, mdd_count_female = 0, 0\n",
        "for sample in eeg_label_female:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count_female += 1\n",
        "  else:\n",
        "      healthy_count_female += 1\n",
        "\n",
        "print(f\"Number of MDD female participants: {mdd_count_female}\")\n",
        "print(f\"Number of Healthy female participants: {healthy_count_female}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.utils import resample, shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f084adc-52ef-4861-d7f1-bc2dcccfd715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_female: 1920\n",
            "Length of filtered eeg_data_female: 1920\n",
            "1920\n",
            "160\n",
            "32\n",
            "(384, 64, 4975)\n"
          ]
        }
      ],
      "source": [
        "ll = eeg_label_female\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_female = [sample for i, sample in enumerate(eeg_label_female) if i not in indices_to_remove]\n",
        "eeg_data_female = [data for i, data in enumerate(eeg_data_female) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_female:\", len(eeg_label_female))\n",
        "print(\"Length of filtered eeg_data_female:\", len(eeg_data_female))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = eeg_label_female\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 16\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_female):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data_female[i])\n",
        "    y_train.append(eeg_label_female[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YePAc3t2RgS"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Data preparation steps\n",
        "ll = eeg_label_female\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_female = [sample for i, sample in enumerate(eeg_label_female) if i not in indices_to_remove]\n",
        "eeg_data_female = [data for i, data in enumerate(eeg_data_female) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_female:\", len(eeg_label_female))\n",
        "print(\"Length of filtered eeg_data_female:\", len(eeg_data_female))\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = eeg_label_female\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 16\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from balanced_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_label_female for sample IDs in balanced_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_female):\n",
        "    if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X = np.array([eeg_data_female[i] for i in indices])\n",
        "y = np.array([1 if label[1] == \"MDD\" else 0 for label in eeg_label_female if label[0] in unique_sample_ids])\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X))\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "# Define the EEGClassifier class\n",
        "class EEGClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = SVC(C=0.4, kernel='rbf')\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "        self.model = SVC(C=0.4, kernel='rbf', class_weight=class_weight_dict)\n",
        "        self.model.fit(X_train_flattened, y_train)\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
        "        y_pred = self.model.predict(X_test_flattened)\n",
        "        return {\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'precision': precision_score(y_test, y_pred, average='macro'),\n",
        "            'recall': recall_score(y_test, y_pred, average='macro'),\n",
        "            'f1_score': f1_score(y_test, y_pred, average='macro'),\n",
        "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    global X, y\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    val_accuracies = []\n",
        "    val_precisions = []\n",
        "    val_recalls = []\n",
        "    val_f1_scores = []\n",
        "    val_confusion_matrices = []\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold = X_train[train_index]\n",
        "        y_train_fold = y_train[train_index]\n",
        "        X_val_fold = X_train[val_index]\n",
        "        y_val_fold = y_train[val_index]\n",
        "\n",
        "        classifier.train(X_train_fold, y_train_fold)\n",
        "\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Accuracy: {train_metrics[\"accuracy\"]}, Precision: {train_metrics[\"precision\"]}, '\n",
        "              f'Recall: {train_metrics[\"recall\"]}, F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Accuracy: {val_metrics[\"accuracy\"]}, Precision: {val_metrics[\"precision\"]}, '\n",
        "              f'Recall: {val_metrics[\"recall\"]}, F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        print('Validation Confusion Matrix:')\n",
        "        print(val_metrics['confusion_matrix'])\n",
        "        print()\n",
        "\n",
        "        val_accuracies.append(val_metrics[\"accuracy\"])\n",
        "        val_precisions.append(val_metrics[\"precision\"])\n",
        "        val_recalls.append(val_metrics[\"recall\"])\n",
        "        val_f1_scores.append(val_metrics[\"f1_score\"])\n",
        "        val_confusion_matrices.append(val_metrics[\"confusion_matrix\"])\n",
        "\n",
        "    # Calculate average validation metrics\n",
        "    avg_val_accuracy = np.mean(val_accuracies)\n",
        "    avg_val_precision = np.mean(val_precisions)\n",
        "    avg_val_recall = np.mean(val_recalls)\n",
        "    avg_val_f1_score = np.mean(val_f1_scores)\n",
        "    avg_val_confusion_matrix = np.mean(val_confusion_matrices, axis=0)\n",
        "\n",
        "    print(f'Average Validation Accuracy: {avg_val_accuracy}')\n",
        "    print(f'Average Validation Precision: {avg_val_precision}')\n",
        "    print(f'Average Validation Recall: {avg_val_recall}')\n",
        "    print(f'Average Validation F1 Score: {avg_val_f1_score}')\n",
        "    print(f'Average Validation Confusion Matrix: \\n{avg_val_confusion_matrix}')\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_metrics = classifier.evaluate(X_test, y_test)\n",
        "    print(f'Test Results - Accuracy: {test_metrics[\"accuracy\"]}, Precision: {test_metrics[\"precision\"]}, '\n",
        "          f'Recall: {test_metrics[\"recall\"]}, F1 Score: {test_metrics[\"f1_score\"]}')\n",
        "    print('Test Confusion Matrix:')\n",
        "    print(test_metrics['confusion_matrix'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "cpqCw3auJOVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439487df-9881-4a1c-fe98-9ccf5dd284b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_female: 1920\n",
            "Length of filtered eeg_data_female: 1920\n",
            "1920\n",
            "160\n",
            "32\n",
            "(384, 64, 4975)\n",
            "Fold 1:\n",
            "Training Results - Accuracy: 0.758957654723127, Precision: 0.7720868409393, Recall: 0.7606979113601631, F1 Score: 0.7567874272010962\n",
            "Validation Results - Accuracy: 0.4675324675324675, Precision: 0.44565217391304346, Recall: 0.45426829268292684, F1 Score: 0.43675289919714544\n",
            "Validation Confusion Matrix:\n",
            "[[ 16 16]\n",
            " [ 17 13]]\n",
            "\n",
            "Fold 2:\n",
            "Training Results - Accuracy: 0.739413680781759, Precision: 0.8119015047879616, Recall: 0.7523627075351214, F1 Score: 0.7294200599330161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results - Accuracy: 0.6493506493506493, Precision: 0.6274509803921569, Recall: 0.5921985815602837, F1 Score: 0.586597733147743\n",
            "Validation Confusion Matrix:\n",
            "[[19  13]\n",
            " [9  22]]\n",
            "\n",
            "Fold 3:\n",
            "Training Results - Accuracy: 0.7947882736156352, Precision: 0.8139415340604327, Recall: 0.7983391385608699, F1 Score: 0.7928097783586325\n",
            "Validation Results - Accuracy: 0.5844155844155844, Precision: 0.5731523378582202, Recall: 0.5663474692202461, F1 Score: 0.5631205673758866\n",
            "Validation Confusion Matrix:\n",
            "[[16  15]\n",
            " [11  20]]\n",
            "\n",
            "Fold 4:\n",
            "Training Results - Accuracy: 0.7850162866449512, Precision: 0.8046134899583175, Recall: 0.7744771660264618, F1 Score: 0.7761797454931071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results - Accuracy: 0.4805194805194805, Precision: 0.5545454545454546, Recall: 0.5488888888888889, F1 Score: 0.478319783197832\n",
            "Validation Confusion Matrix:\n",
            "[[11  15]\n",
            " [17  18]]\n",
            "\n",
            "Fold 5:\n",
            "Training Results - Accuracy: 0.7597402597402597, Precision: 0.7767857142857143, Recall: 0.7563713080168777, F1 Score: 0.754258851942899\n",
            "Validation Results - Accuracy: 0.4342105263157895, Precision: 0.44588235294117645, Recall: 0.45168067226890757, F1 Score: 0.4261633011413521\n",
            "Validation Confusion Matrix:\n",
            "[[14 15]\n",
            " [19 12]]\n",
            "\n",
            "Average Validation Accuracy: 0.5232901639344261\n",
            "Average Validation Precision: 0.529764857983417\n",
            "Average Validation Recall: 0.5223240753314168\n",
            "Average Validation F1 Score: 0.49828766354080567\n",
            "Average Validation Confusion Matrix: \n",
            "[[15.2 14.8]\n",
            " [14.6 17]]\n",
            "Test Results - Accuracy: 0.5857142857142855, Precision: 0.4284750337381916, Recall: 0.58584750337381916, F1 Score: 0.5684750337381916\n",
            "Test Confusion Matrix:\n",
            "[[22 16]\n",
            " [18 21]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
