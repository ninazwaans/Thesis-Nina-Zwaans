{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the CNN implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my CNN analysis."
      ],
      "metadata": {
        "id": "hPhlMiQr3BGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj8lCByp9dFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a3c140-33ef-44fb-f111-c993619545db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB1g1ok5-QKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a88989-2013-45ed-e2dc-f963030018d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 32, 4975)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0657c72-4b50-4f47-fce1-1e67cc3a142d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)\n",
        "\n",
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "baa2UWnEsOAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727eddb4-53df-49c8-d0f7-95163185db1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 64, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = ec_eeg_labels\n",
        "eeg_labels.shape"
      ],
      "metadata": {
        "id": "o_NT5lbT6CgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b9e9fd-7519-42a6-8ea3-6a16d7f9f53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD participants: {mdd_count}\")\n",
        "print(f\"Number of Healthy participants: {healthy_count}\")"
      ],
      "metadata": {
        "id": "6o2e6442_rix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420a1d48-a403-4b03-bcc2-6aed5810a720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD participants: 3780\n",
            "Number of Healthy participants: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting data for male participants"
      ],
      "metadata": {
        "id": "VMj3gbuquMBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_participants = pd.read_pickle('/content/drive/MyDrive/TD-BRAIN/TDBRAIN_participants_V2_data/df_participants.pkl')\n",
        "male_count = 0\n",
        "\n",
        "eeg_data_male = []\n",
        "eeg_label_male = []\n",
        "\n",
        "for i, labels in enumerate(eeg_labels):\n",
        "     sample_id = labels[0]\n",
        "     index = df_participants.loc[df_participants['participants_ID'] == sample_id].index\n",
        "     if [value for value in df_participants.loc[index, 'gender']][0] == 0:\n",
        "       eeg_data_male.append(eeg_data[i])\n",
        "       eeg_label_male.append(eeg_labels[i])\n",
        "\n",
        "eeg_data_male = np.array(eeg_data_male)\n",
        "eeg_label_male = np.array(eeg_label_male)\n",
        "\n",
        "print(eeg_data_male.shape, eeg_label_male.shape)"
      ],
      "metadata": {
        "id": "BgccUbq82-sH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dbb0fe-fed7-41b9-d50d-8bc8f0fe87ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2412, 64, 4975) (2412, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count_male, mdd_count_male = 0, 0\n",
        "for sample in eeg_label_male:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count_male += 1\n",
        "  else:\n",
        "      healthy_count_male += 1\n",
        "\n",
        "print(f\"Number of MDD male participants: {mdd_count_male}\")\n",
        "print(f\"Number of Healthy male participants: {healthy_count_male}\")"
      ],
      "metadata": {
        "id": "9gco48mX3IoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e5a36e-a107-41e0-83bb-d0942e9d7ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD male participants: 2040\n",
            "Number of Healthy male participants: 372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyjPRqmaPN8"
      },
      "source": [
        "### **Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f645635-b9dd-4556-c77d-2e07c0e8d647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_male: 2328\n",
            "Length of filtered eeg_data_male: 2328\n",
            "2328\n",
            "194\n",
            "62\n",
            "(744, 64, 4975)\n"
          ]
        }
      ],
      "source": [
        "ll = eeg_label_male\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_male = [sample for i, sample in enumerate(eeg_label_male) if i not in indices_to_remove]\n",
        "eeg_data_male = [data for i, data in enumerate(eeg_data_male) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_male:\", len(eeg_label_male))\n",
        "print(\"Length of filtered eeg_data_male:\", len(eeg_data_male))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = eeg_label_male\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 31\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from balanced_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_label_male for sample IDs in balanced_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_male):\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data_male[i])\n",
        "    y_train.append(eeg_label_male[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfzmsJCA1voj"
      },
      "outputs": [],
      "source": [
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(64, 4975), lstm_units=64):\n",
        "        self.input_shape = input_shape\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "        from keras.metrics import Precision, Recall\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=self.input_shape))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(LSTM(units=128, return_sequences=True))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(units=self.lstm_units))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=64, activation='sigmoid'))\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=1):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=0)\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f'Test Loss: {loss}, Test Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        print(f'F1 Score: {f1}')\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "        print('Confusion Matrix:')\n",
        "        print(cm)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVv8Bu0cYnq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b6c37b-f3de-45ce-ace7-a88b29b0ca4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Test Loss: 0.7013103365898132, Test Accuracy: 0.5277311205863953, Precision: 0.532567024230957, Recall: 0.46644294261932373\n",
            "19/19 [==============================] - 2s 46ms/step\n",
            "F1 Score: 0.4973166368515206\n",
            "Confusion Matrix:\n",
            "[[175 122]\n",
            " [159 139]]\n",
            "Training Results - Loss: 0.7013103365898132, Accuracy: 0.5277311205863953, Precision: 0.532567024230957, Recall: 0.46644294261932373, F1 Score: 0.4973166368515206\n",
            "Test Loss: 0.7517521381378174, Test Accuracy: 0.42281877994537354, Precision: 0.42500001192092896, Recall: 0.45945945382118225\n",
            "5/5 [==============================] - 0s 44ms/step\n",
            "F1 Score: 0.44155844155844154\n",
            "Confusion Matrix:\n",
            "[[29 46]\n",
            " [40 34]]\n",
            "Validation Results - Loss: 0.7517521381378174, Accuracy: 0.42281877994537354, Precision: 0.42500001192092896, Recall: 0.45945945382118225, F1 Score: 0.44155844155844154\n",
            "\n",
            "Fold 2:\n",
            "Test Loss: 0.764914870262146, Test Accuracy: 0.48739495873451233, Precision: 0.48341232538223267, Recall: 0.34228187799453735\n",
            "19/19 [==============================] - 1s 42ms/step\n",
            "F1 Score: 0.40078585461689586\n",
            "Confusion Matrix:\n",
            "[[188 109]\n",
            " [196 102]]\n",
            "Training Results - Loss: 0.764914870262146, Accuracy: 0.48739495873451233, Precision: 0.48341232538223267, Recall: 0.34228187799453735, F1 Score: 0.40078585461689586\n",
            "Test Loss: 0.7830084562301636, Test Accuracy: 0.449664443731308, Precision: 0.4333333373069763, Recall: 0.3513513505458832\n",
            "5/5 [==============================] - 0s 45ms/step\n",
            "F1 Score: 0.3880597014925374\n",
            "Confusion Matrix:\n",
            "[[41 34]\n",
            " [48 26]]\n",
            "Validation Results - Loss: 0.7830084562301636, Accuracy: 0.449664443731308, Precision: 0.4333333373069763, Recall: 0.3513513505458832, F1 Score: 0.3880597014925374\n",
            "\n",
            "Fold 3:\n",
            "Test Loss: 0.7510035634040833, Test Accuracy: 0.5092437267303467, Precision: 0.505643367767334, Recall: 0.7542087435722351\n",
            "19/19 [==============================] - 1s 46ms/step\n",
            "F1 Score: 0.6054054054054054\n",
            "Confusion Matrix:\n",
            "[[ 79 219]\n",
            " [ 73 224]]\n",
            "Training Results - Loss: 0.7510035634040833, Accuracy: 0.5092437267303467, Precision: 0.505643367767334, Recall: 0.7542087435722351, F1 Score: 0.6054054054054054\n",
            "Test Loss: 0.7564682960510254, Test Accuracy: 0.4966442883014679, Precision: 0.5, Recall: 0.6800000071525574\n",
            "5/5 [==============================] - 0s 41ms/step\n",
            "F1 Score: 0.576271186440678\n",
            "Confusion Matrix:\n",
            "[[23 51]\n",
            " [24 51]]\n",
            "Validation Results - Loss: 0.7564682960510254, Accuracy: 0.4966442883014679, Precision: 0.5, Recall: 0.6800000071525574, F1 Score: 0.576271186440678\n",
            "\n",
            "Fold 4:\n",
            "Test Loss: 0.7440953850746155, Test Accuracy: 0.489075630903244, Precision: 0.48929664492607117, Recall: 0.5387205481529236\n",
            "19/19 [==============================] - 1s 48ms/step\n",
            "F1 Score: 0.5128205128205128\n",
            "Confusion Matrix:\n",
            "[[131 167]\n",
            " [137 160]]\n",
            "Training Results - Loss: 0.7440953850746155, Accuracy: 0.489075630903244, Precision: 0.48929664492607117, Recall: 0.5387205481529236, F1 Score: 0.5128205128205128\n",
            "Test Loss: 0.735588788986206, Test Accuracy: 0.4966442883014679, Precision: 0.5, Recall: 0.5733333230018616\n",
            "5/5 [==============================] - 0s 51ms/step\n",
            "F1 Score: 0.5341614906832299\n",
            "Confusion Matrix:\n",
            "[[31 43]\n",
            " [32 43]]\n",
            "Validation Results - Loss: 0.735588788986206, Accuracy: 0.4966442883014679, Precision: 0.5, Recall: 0.5733333230018616, F1 Score: 0.5341614906832299\n",
            "\n",
            "Fold 5:\n",
            "Test Loss: 0.7456420063972473, Test Accuracy: 0.4848993420600891, Precision: 0.4903225898742676, Recall: 0.7651006579399109\n",
            "19/19 [==============================] - 1s 47ms/step\n",
            "F1 Score: 0.5976408912188729\n",
            "Confusion Matrix:\n",
            "[[ 61 237]\n",
            " [ 70 228]]\n",
            "Training Results - Loss: 0.7456420063972473, Accuracy: 0.4848993420600891, Precision: 0.4903225898742676, Recall: 0.7651006579399109, F1 Score: 0.5976408912188729\n",
            "Test Loss: 0.7002078890800476, Test Accuracy: 0.5405405163764954, Precision: 0.5245901346206665, Recall: 0.8648648858070374\n",
            "5/5 [==============================] - 0s 44ms/step\n",
            "F1 Score: 0.6530612244897959\n",
            "Confusion Matrix:\n",
            "[[16 58]\n",
            " [10 64]]\n",
            "Validation Results - Loss: 0.7002078890800476, Accuracy: 0.5405405163764954, Precision: 0.5245901346206665, Recall: 0.8648648858070374, F1 Score: 0.6530612244897959\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def main():\n",
        "    global classifier\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}