{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the LSTM implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my LSTM analysis."
      ],
      "metadata": {
        "id": "EjCCIQuw1md6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kj8lCByp9dFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eca0ae8-0691-4453-cf9f-2d9768bc0d37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nB1g1ok5-QKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaecb45b-1610-41a4-9c7d-0d9d6eae32db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 26, 4975)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c47ad6-05b7-4bca-e71a-f2e6246826fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)"
      ],
      "metadata": {
        "id": "4yOz0jBErINx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec72f6b-517b-4280-ef17-31947a664809"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "mhbmIqENrIWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd5cf8e-d4f7-43ff-bd42-63b38b8fb47e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 52, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = ec_eeg_labels"
      ],
      "metadata": {
        "id": "0xTKQqAMrNHf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD participants: {mdd_count}\")\n",
        "print(f\"Number of Healthy participants: {healthy_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2e6442_rix",
        "outputId": "089a9951-9c3f-421a-b2e4-f313f345db85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD participants: 3780\n",
            "Number of Healthy participants: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting data for male participants"
      ],
      "metadata": {
        "id": "VMj3gbuquMBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the participants data\n",
        "df_participants = pd.read_pickle('/content/drive/MyDrive/TD-BRAIN/TDBRAIN_participants_V2_data/df_participants.pkl')\n",
        "\n",
        "# Prepare lists to hold the filtered data and labels\n",
        "eeg_data_male = []\n",
        "eeg_label_male = []\n",
        "\n",
        "# Loop over each label in your existing eeg_labels list\n",
        "for i, labels in enumerate(eeg_labels):\n",
        "    sample_id = labels[0]\n",
        "    index = df_participants.loc[df_participants['participants_ID'] == sample_id].index\n",
        "\n",
        "    if not index.empty:  # Check if the index is not empty\n",
        "        participant_gender = df_participants.loc[index, 'gender'].values[0]\n",
        "        participant_condition = labels[1]  # Assuming the condition (MDD/HEALTHY) is stored in labels[1]\n",
        "\n",
        "        # Check if participant is male and has the condition \"Healthy\" or \"MDD\"\n",
        "        if participant_gender == 0 and (participant_condition == \"HEALTHY\" or participant_condition == \"MDD\"):\n",
        "            eeg_data_male.append(eeg_data[i])\n",
        "            eeg_label_male.append(labels)\n",
        "\n",
        "# Convert lists to NumPy arrays for further processing\n",
        "eeg_data_male = np.array(eeg_data_male)\n",
        "eeg_label_male = np.array(eeg_label_male)\n",
        "\n",
        "# Output the shape of the arrays to verify the results\n",
        "print(f\"Shape of male EEG data: {eeg_data_male.shape}\")\n",
        "print(f\"Shape of male EEG labels: {eeg_label_male.shape}\")\n"
      ],
      "metadata": {
        "id": "AO_353PuuLbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d368ee-01fa-4e92-d8fd-a890605e6068"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of male EEG data: (2412, 52, 4975)\n",
            "Shape of male EEG labels: (2412, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count_male, mdd_count_male = 0, 0\n",
        "for sample in eeg_label_male:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count_male += 1\n",
        "  else:\n",
        "      healthy_count_male += 1\n",
        "\n",
        "print(f\"Number of MDD male participants: {mdd_count_male}\")\n",
        "print(f\"Number of Healthy male participants: {healthy_count_male}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LmB6cG4_tyz",
        "outputId": "67bbbc34-f8f3-4d21-b20e-6c077f5d2d70"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD male participants: 2040\n",
            "Number of Healthy male participants: 372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4487da2-c644-4b7d-e851-1375f601b39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_male: 2328\n",
            "Length of filtered eeg_data_male: 2328\n",
            "(384, 52, 4975)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Filtering eeg_label_male and eeg_data_male\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(eeg_label_male):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_male = [sample for i, sample in enumerate(eeg_label_male) if i not in indices_to_remove]\n",
        "eeg_data_male = [data for i, data in enumerate(eeg_data_male) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_male:\", len(eeg_label_male))\n",
        "print(\"Length of filtered eeg_data_male:\", len(eeg_data_male))\n",
        "\n",
        "# Undersampling and preparing training data\n",
        "ll = eeg_label_male\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "\n",
        "num_samples_per_class = 16\n",
        "indices_mdd = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_healthy = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "\n",
        "# Ensure we have at least 16 samples of each class\n",
        "if len(indices_mdd) < num_samples_per_class or len(indices_healthy) < num_samples_per_class:\n",
        "    raise ValueError(\"Not enough samples to balance the classes with 16 samples each.\")\n",
        "\n",
        "undersampled_mdd = np.random.choice(indices_mdd, num_samples_per_class, replace=False)\n",
        "undersampled_healthy = np.random.choice(indices_healthy, num_samples_per_class, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([undersampled_mdd, undersampled_healthy])\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from balanced_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "\n",
        "# Extract all indices from eeg_labels for sample IDs in balanced_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_male):\n",
        "    if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data_male[i])\n",
        "    y_train.append(eeg_label_male[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "    sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gVv8Bu0cYnq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75e1678-dc32-4697-f6b7-0e594ad5d3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Training Results - Loss: 4.768543720245361, Accuracy: 0.7035830616950989, Precision: 0.6823529601097107, Recall: 0.758169949054718, F1 Score: 0.718266253869969\n",
            "Validation Results - Loss: 4.8460612297058105, Accuracy: 0.5584415793418884, Precision: 0.5581395626068115, Recall: 0.6153846383094788, F1 Score: 0.5853658536585366\n",
            "\n",
            "Fold 2:\n",
            "Training Results - Loss: 4.587101936340332, Accuracy: 0.8273615837097168, Precision: 0.7976190447807312, Recall: 0.8758170008659363, F1 Score: 0.8348909657320872\n",
            "Validation Results - Loss: 4.801440238952637, Accuracy: 0.5844155550003052, Precision: 0.6060606241226196, Recall: 0.5128205418586731, F1 Score: 0.5555555555555556\n",
            "\n",
            "Fold 3:\n",
            "Training Results - Loss: 6.511475086212158, Accuracy: 0.837133526802063, Precision: 0.8209876418113708, Recall: 0.8636363744735718, F1 Score: 0.8417721518987342\n",
            "Validation Results - Loss: 6.784726619720459, Accuracy: 0.5584415793418884, Precision: 0.5454545617103577, Recall: 0.6315789222717285, F1 Score: 0.5853658536585366\n",
            "\n",
            "Fold 4:\n",
            "Training Results - Loss: 6.723092079162598, Accuracy: 0.8045602440834045, Precision: 0.8051947951316833, Recall: 0.8051947951316833, F1 Score: 0.8051948051948051\n",
            "Validation Results - Loss: 6.919004917144775, Accuracy: 0.7142857313156128, Precision: 0.6818181872367859, Recall: 0.7894737124443054, F1 Score: 0.7317073170731707\n",
            "\n",
            "Fold 5:\n",
            "Training Results - Loss: 6.062843322753906, Accuracy: 0.7857142686843872, Precision: 0.7528735399246216, Recall: 0.850649356842041, F1 Score: 0.7987804878048782\n",
            "Validation Results - Loss: 6.142409801483154, Accuracy: 0.7368420958518982, Precision: 0.7045454382896423, Recall: 0.8157894611358643, F1 Score: 0.7560975609756098\n",
            "\n",
            "Overall Training Metrics:\n",
            "{'loss': 5.7306112289428714, 'accuracy': 0.7916705369949341, 'precision': 0.7718055963516235, 'recall': 0.83069349527359, 'f1_score': 0.7997809329000948, 'confusion_matrix': array([[115.6,  38. ],\n",
            "       [ 26. , 127.6]])}\n",
            "\n",
            "Overall Validation Metrics:\n",
            "{'loss': 5.898728561401367, 'accuracy': 0.6304853081703186, 'precision': 0.6192036747932435, 'recall': 0.67300945520401, 'f1_score': 0.6428184281842817, 'confusion_matrix': array([[22.6, 15.8],\n",
            "       [12.6, 25.8]])}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, BatchNormalization, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(52, 4975)):\n",
        "        self.input_shape = input_shape\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units=64, input_shape=self.input_shape, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(LSTM(units=64, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(LSTM(units=32, kernel_regularizer=l2(0.01)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(units=32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def early_stopping(self):\n",
        "        from keras.callbacks import EarlyStopping\n",
        "        return EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0)\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=10, batch_size=1):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=0, callbacks=[self.early_stopping()])\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        y_pred = self.model.predict(X_test, verbose=0)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X, verbose=0)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "def main():\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    overall_train_metrics = []\n",
        "    overall_val_metrics = []\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "        overall_train_metrics.append(train_metrics)\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        overall_val_metrics.append(val_metrics)\n",
        "        print()\n",
        "\n",
        "    # Calculate and print overall metrics\n",
        "    def calculate_overall_metrics(metrics_list):\n",
        "        avg_metrics = {}\n",
        "        for key in metrics_list[0].keys():\n",
        "            avg_metrics[key] = np.mean([metrics[key] for metrics in metrics_list], axis=0)\n",
        "        return avg_metrics\n",
        "\n",
        "    overall_train_metrics = calculate_overall_metrics(overall_train_metrics)\n",
        "    overall_val_metrics = calculate_overall_metrics(overall_val_metrics)\n",
        "\n",
        "    print(\"Overall Training Metrics:\")\n",
        "    print(overall_train_metrics)\n",
        "    print(\"\\nOverall Validation Metrics:\")\n",
        "    print(overall_val_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUXq0i0IqBgK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}