{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the CNN implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my CNN analysis."
      ],
      "metadata": {
        "id": "T_-Wzz-o2olK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8lCByp9dFa",
        "outputId": "c7152933-fcf9-4885-c357-cea1c6426952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ],
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB1g1ok5-QKw",
        "outputId": "248b969a-89d7-48d2-8e46-1fd143c5bf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 32, 4975)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ],
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ],
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad63ecf-9276-443d-b9d7-e25e309ddc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)\n",
        "\n",
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "5YrMjz4hnTVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f64a5c9-7bbd-40a1-9f3a-f681c90b97f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 64, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = eo_eeg_labels"
      ],
      "metadata": {
        "id": "_aa-u2qUnYkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD patient: {mdd_count}\")\n",
        "print(f\"Number of Healthy patient: {healthy_count}\")"
      ],
      "metadata": {
        "id": "_uu4_RU-iPuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881107dc-007c-4204-e616-a0a0282f3de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD patient: 3780\n",
            "Number of Healthy patient: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Undersampling the majority class (MDD)**"
      ],
      "metadata": {
        "id": "V6GT2C-ztrw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Healthy patients EEG data"
      ],
      "metadata": {
        "id": "5x1kwwjbvo_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Data**"
      ],
      "metadata": {
        "id": "ERtA6F0faDBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Converting the labels to binary**\n",
        "1 -> MDD\n",
        "\n",
        "0 -> HEALTHY"
      ],
      "metadata": {
        "id": "CpyjPRqmaPN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll = ec_eeg_labels\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "ec_eeg_labels = [sample for i, sample in enumerate(ec_eeg_labels) if i not in indices_to_remove]\n",
        "eeg_data = [data for i, data in enumerate(eeg_data) if i not in indices_to_remove]\n",
        "print(\"Length of filtered ec_eeg_labels:\", len(ec_eeg_labels))\n",
        "print(\"Length of filtered eeg_data:\", len(eeg_data))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = ec_eeg_labels\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 47\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(ec_eeg_labels):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data[i])\n",
        "    y_train.append(eeg_labels[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ],
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a509e63c-a97f-4ebd-b299-5f0fd17183d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered ec_eeg_labels: 4248\n",
            "Length of filtered eeg_data: 4248\n",
            "4248\n",
            "354\n",
            "94\n",
            "(1128, 64, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of MDD patients:\", len(undersampled))\n",
        "print(\"Number of Healthy patients:\", len(indices_min))\n"
      ],
      "metadata": {
        "id": "ZZahRy9EHi-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0c1224-dc02-4917-fc81-01e4e97593a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD patients: 47\n",
            "Number of Healthy patients: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_train - contains sample_ids with actual labels\n",
        "\n",
        "X_train - contains data"
      ],
      "metadata": {
        "id": "At4ZwarATS9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(64, 4975), lstm_units=64):\n",
        "        self.input_shape = input_shape\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "        from keras.metrics import Precision, Recall\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=self.input_shape))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(LSTM(units=128, return_sequences=True))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(units=self.lstm_units))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=64, activation='sigmoid'))\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=1):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=0)\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f'Test Loss: {loss}, Test Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        print(f'F1 Score: {f1}')\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "        print('Confusion Matrix:')\n",
        "        print(cm)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "PfzmsJCA1voj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def main():\n",
        "    global classifier\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "vzK2FNlQU0pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051d7888-b338-4283-cfc8-e449ef01ed06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Test Loss: 0.6996328830718994, Test Accuracy: 0.5698447823524475, Precision: 0.6661316156387329, Recall: 0.6974790096282959\n",
            "29/29 [==============================] - 1s 13ms/step\n",
            "F1 Score: 0.6814449917898194\n",
            "Confusion Matrix:\n",
            "[[ 99 208]\n",
            " [180 415]]\n",
            "Training Results - Loss: 0.6996328830718994, Accuracy: 0.5698447823524475, Precision: 0.6661316156387329, Recall: 0.6974790096282959, F1 Score: 0.6814449917898194\n",
            "Test Loss: 0.6793634295463562, Test Accuracy: 0.5840708017349243, Precision: 0.6571428775787354, Recall: 0.7718120813369751\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.7098765432098766\n",
            "Confusion Matrix:\n",
            "[[ 17  60]\n",
            " [ 34 115]]\n",
            "Validation Results - Loss: 0.6793634295463562, Accuracy: 0.5840708017349243, Precision: 0.6571428775787354, Recall: 0.7718120813369751, F1 Score: 0.7098765432098766\n",
            "\n",
            "Fold 2:\n",
            "Test Loss: 0.737827479839325, Test Accuracy: 0.47006651759147644, Precision: 0.6620498895645142, Recall: 0.40168067812919617\n",
            "29/29 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.5\n",
            "Confusion Matrix:\n",
            "[[185 122]\n",
            " [356 239]]\n",
            "Training Results - Loss: 0.737827479839325, Accuracy: 0.47006651759147644, Precision: 0.6620498895645142, Recall: 0.40168067812919617, F1 Score: 0.5\n",
            "Test Loss: 0.7490226030349731, Test Accuracy: 0.48672565817832947, Precision: 0.6701030731201172, Recall: 0.43624159693717957\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.5284552845528454\n",
            "Confusion Matrix:\n",
            "[[45 32]\n",
            " [84 65]]\n",
            "Validation Results - Loss: 0.7490226030349731, Accuracy: 0.48672565817832947, Precision: 0.6701030731201172, Recall: 0.43624159693717957, F1 Score: 0.5284552845528454\n",
            "\n",
            "Fold 3:\n",
            "Test Loss: 0.6826958656311035, Test Accuracy: 0.5576496720314026, Precision: 0.6731448769569397, Recall: 0.6403361558914185\n",
            "29/29 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.6563307493540053\n",
            "Confusion Matrix:\n",
            "[[122 185]\n",
            " [214 381]]\n",
            "Training Results - Loss: 0.6826958656311035, Accuracy: 0.5576496720314026, Precision: 0.6731448769569397, Recall: 0.6403361558914185, F1 Score: 0.6563307493540053\n",
            "Test Loss: 0.6874769330024719, Test Accuracy: 0.5442478060722351, Precision: 0.6716417670249939, Recall: 0.6040268540382385\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.6360424028268551\n",
            "Confusion Matrix:\n",
            "[[33 44]\n",
            " [59 90]]\n",
            "Validation Results - Loss: 0.6874769330024719, Accuracy: 0.5442478060722351, Precision: 0.6716417670249939, Recall: 0.6040268540382385, F1 Score: 0.6360424028268551\n",
            "\n",
            "Fold 4:\n",
            "Test Loss: 0.7411225438117981, Test Accuracy: 0.45847177505493164, Precision: 0.6866196990013123, Recall: 0.32773110270500183\n",
            "29/29 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.4436860068259385\n",
            "Confusion Matrix:\n",
            "[[219  89]\n",
            " [400 195]]\n",
            "Training Results - Loss: 0.7411225438117981, Accuracy: 0.45847177505493164, Precision: 0.6866196990013123, Recall: 0.32773110270500183, F1 Score: 0.4436860068259385\n",
            "Test Loss: 0.7484375834465027, Test Accuracy: 0.4355555474758148, Precision: 0.6447368264198303, Recall: 0.3288590610027313\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.4355555555555556\n",
            "Confusion Matrix:\n",
            "[[ 49  27]\n",
            " [100  49]]\n",
            "Validation Results - Loss: 0.7484375834465027, Accuracy: 0.4355555474758148, Precision: 0.6447368264198303, Recall: 0.3288590610027313, F1 Score: 0.4355555555555556\n",
            "\n",
            "Fold 5:\n",
            "Test Loss: 0.7376220226287842, Test Accuracy: 0.40642303228378296, Precision: 0.6327433586120605, Recall: 0.23993287980556488\n",
            "29/29 [==============================] - 0s 12ms/step\n",
            "F1 Score: 0.3479318734793187\n",
            "Confusion Matrix:\n",
            "[[224  83]\n",
            " [453 143]]\n",
            "Training Results - Loss: 0.7376220226287842, Accuracy: 0.40642303228378296, Precision: 0.6327433586120605, Recall: 0.23993287980556488, F1 Score: 0.3479318734793187\n",
            "Test Loss: 0.7393298745155334, Test Accuracy: 0.3911111056804657, Precision: 0.6279069781303406, Recall: 0.18243242800235748\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.28272251308900526\n",
            "Confusion Matrix:\n",
            "[[ 61  16]\n",
            " [121  27]]\n",
            "Validation Results - Loss: 0.7393298745155334, Accuracy: 0.3911111056804657, Precision: 0.6279069781303406, Recall: 0.18243242800235748, F1 Score: 0.28272251308900526\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LxQlU5jnQIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}