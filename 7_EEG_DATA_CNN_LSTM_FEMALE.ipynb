{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the CNN implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my CNN analysis."
      ],
      "metadata": {
        "id": "sRRL5w1_2O0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj8lCByp9dFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd1dadf-b4a0-42f8-dca1-471910e5d2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB1g1ok5-QKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90ab7ea-e2e5-4827-9a03-b1158d9c702e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 32, 4975)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59dcfa35-bf04-4bc4-866d-aa6439f661e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)\n",
        "\n",
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "UBOz200Wpqq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e53159d-616c-430e-be54-5ecff7037a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 32, 4975)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 64, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = ec_eeg_labels"
      ],
      "metadata": {
        "id": "tRyf_EY3psgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD participants: {mdd_count}\")\n",
        "print(f\"Number of Healthy participants: {healthy_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2e6442_rix",
        "outputId": "88e1ba4e-ad7a-4771-aba9-136a03d066e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD participants: 3780\n",
            "Number of Healthy participants: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting data for female participants"
      ],
      "metadata": {
        "id": "VMj3gbuquMBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the participants data\n",
        "df_participants = pd.read_pickle('/content/drive/MyDrive/TD-BRAIN/TDBRAIN_participants_V2_data/df_participants.pkl')\n",
        "\n",
        "# Prepare lists to hold the filtered data and labels\n",
        "eeg_data_female = []\n",
        "eeg_label_female = []\n",
        "\n",
        "# Loop over each label in your existing eeg_labels list\n",
        "for i, labels in enumerate(eeg_labels):\n",
        "    sample_id = labels[0]\n",
        "    index = df_participants.loc[df_participants['participants_ID'] == sample_id].index\n",
        "\n",
        "    if not index.empty:  # Check if the index is not empty\n",
        "        participant_gender = df_participants.loc[index, 'gender'].values[0]\n",
        "        participant_condition = labels[1]  # Assuming the condition (MDD/HEALTHY) is stored in labels[1]\n",
        "\n",
        "        # Check if participant is female and has the condition \"Healthy\" or \"MDD\"\n",
        "        if participant_gender == 1 and (participant_condition == \"HEALTHY\" or participant_condition == \"MDD\"):\n",
        "            eeg_data_female.append(eeg_data[i])\n",
        "            eeg_label_female.append(labels)\n",
        "\n",
        "# Convert lists to NumPy arrays for further processing\n",
        "eeg_data_female = np.array(eeg_data_female)\n",
        "eeg_label_female = np.array(eeg_label_female)\n",
        "\n",
        "# Output the shape of the arrays to verify the results\n",
        "print(f\"Shape of female EEG data: {eeg_data_female.shape}\")\n",
        "print(f\"Shape of female EEG labels: {eeg_label_female.shape}\")"
      ],
      "metadata": {
        "id": "eveYrU_E3zhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d284492-18c1-4128-b4cd-81d4c2906717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of female EEG data: (1932, 64, 4975)\n",
            "Shape of female EEG labels: (1932, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count_female, mdd_count_female = 0, 0\n",
        "for sample in eeg_label_female:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count_female += 1\n",
        "  else:\n",
        "      healthy_count_female += 1\n",
        "\n",
        "print(f\"Number of MDD female participants: {mdd_count_female}\")\n",
        "print(f\"Number of Healthy female participants: {healthy_count_female}\")"
      ],
      "metadata": {
        "id": "EE942K-n3zpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6aa3630-6ff4-4b0a-9d7a-17d9bf0c819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD female participants: 1740\n",
            "Number of Healthy female participants: 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyjPRqmaPN8"
      },
      "source": [
        "### **Converting the labels to binary**\n",
        "1 -> MDD\n",
        "\n",
        "0 -> HEALTHY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674e972b-6bc0-4c42-eec8-490b77c53549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_female: 1920\n",
            "Length of filtered eeg_data_female: 1920\n",
            "1920\n",
            "160\n",
            "32\n",
            "(384, 64, 4975)\n"
          ]
        }
      ],
      "source": [
        "ll = eeg_label_female\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_female = [sample for i, sample in enumerate(eeg_label_female) if i not in indices_to_remove]\n",
        "eeg_data_female = [data for i, data in enumerate(eeg_data_female) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_female:\", len(eeg_label_female))\n",
        "print(\"Length of filtered eeg_data_female:\", len(eeg_data_female))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = eeg_label_female\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 16\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_female):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data_female[i])\n",
        "    y_train.append(eeg_label_female[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfzmsJCA1voj"
      },
      "outputs": [],
      "source": [
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(64, 4975), lstm_units=64):\n",
        "        self.input_shape = input_shape\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        from keras.models import Sequential\n",
        "        from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "        from keras.metrics import Precision, Recall\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=self.input_shape))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(LSTM(units=128, return_sequences=True))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(units=self.lstm_units))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=64, activation='sigmoid'))\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=20, batch_size=1):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=0)\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f'Test Loss: {loss}, Test Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        print(f'F1 Score: {f1}')\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "        print('Confusion Matrix:')\n",
        "        print(cm)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVv8Bu0cYnq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b696f6-ff7a-4ac4-a02d-2775948bb09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Test Loss: 0.730476975440979, Test Accuracy: 0.5276873111724854, Precision: 0.5279502868652344, Recall: 0.551948070526123\n",
            "10/10 [==============================] - 1s 13ms/step\n",
            "F1 Score: 0.5396825396825397\n",
            "Confusion Matrix:\n",
            "[[77 76]\n",
            " [69 85]]\n",
            "Training Results - Loss: 0.730476975440979, Accuracy: 0.5276873111724854, Precision: 0.5279502868652344, Recall: 0.551948070526123, F1 Score: 0.5396825396825397\n",
            "Test Loss: 0.7136221528053284, Test Accuracy: 0.5194805264472961, Precision: 0.5151515007019043, Recall: 0.44736841320991516\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.4788732394366197\n",
            "Confusion Matrix:\n",
            "[[23 16]\n",
            " [21 17]]\n",
            "Validation Results - Loss: 0.7136221528053284, Accuracy: 0.5194805264472961, Precision: 0.5151515007019043, Recall: 0.44736841320991516, F1 Score: 0.4788732394366197\n",
            "\n",
            "Fold 2:\n",
            "Test Loss: 0.7140184044837952, Test Accuracy: 0.5179153084754944, Precision: 0.5306122303009033, Recall: 0.33766233921051025\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "F1 Score: 0.4126984126984127\n",
            "Confusion Matrix:\n",
            "[[107  46]\n",
            " [102  52]]\n",
            "Training Results - Loss: 0.7140184044837952, Accuracy: 0.5179153084754944, Precision: 0.5306122303009033, Recall: 0.33766233921051025, F1 Score: 0.4126984126984127\n",
            "Test Loss: 0.7472937703132629, Test Accuracy: 0.41558441519737244, Precision: 0.37037035822868347, Recall: 0.2631579041481018\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.30769230769230765\n",
            "Confusion Matrix:\n",
            "[[22 17]\n",
            " [28 10]]\n",
            "Validation Results - Loss: 0.7472937703132629, Accuracy: 0.41558441519737244, Precision: 0.37037035822868347, Recall: 0.2631579041481018, F1 Score: 0.30769230769230765\n",
            "\n",
            "Fold 3:\n",
            "Test Loss: 0.7454760670661926, Test Accuracy: 0.45928338170051575, Precision: 0.451127827167511, Recall: 0.3921568691730499\n",
            "10/10 [==============================] - 0s 13ms/step\n",
            "F1 Score: 0.41958041958041964\n",
            "Confusion Matrix:\n",
            "[[81 73]\n",
            " [93 60]]\n",
            "Training Results - Loss: 0.7454760670661926, Accuracy: 0.45928338170051575, Precision: 0.451127827167511, Recall: 0.3921568691730499, F1 Score: 0.41958041958041964\n",
            "Test Loss: 0.7069993019104004, Test Accuracy: 0.48051947355270386, Precision: 0.48275861144065857, Recall: 0.3589743673801422\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.4117647058823529\n",
            "Confusion Matrix:\n",
            "[[23 15]\n",
            " [25 14]]\n",
            "Validation Results - Loss: 0.7069993019104004, Accuracy: 0.48051947355270386, Precision: 0.48275861144065857, Recall: 0.3589743673801422, F1 Score: 0.4117647058823529\n",
            "\n",
            "Fold 4:\n",
            "Test Loss: 0.7070327401161194, Test Accuracy: 0.49837133288383484, Precision: 0.4957983195781708, Recall: 0.38562092185020447\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "F1 Score: 0.4338235294117647\n",
            "Confusion Matrix:\n",
            "[[94 60]\n",
            " [94 59]]\n",
            "Training Results - Loss: 0.7070327401161194, Accuracy: 0.49837133288383484, Precision: 0.4957983195781708, Recall: 0.38562092185020447, F1 Score: 0.4338235294117647\n",
            "Test Loss: 0.7195578217506409, Test Accuracy: 0.4545454680919647, Precision: 0.45945945382118225, Recall: 0.43589743971824646\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.4473684210526316\n",
            "Confusion Matrix:\n",
            "[[18 20]\n",
            " [22 17]]\n",
            "Validation Results - Loss: 0.7195578217506409, Accuracy: 0.4545454680919647, Precision: 0.45945945382118225, Recall: 0.43589743971824646, F1 Score: 0.4473684210526316\n",
            "\n",
            "Fold 5:\n",
            "Test Loss: 0.7253627777099609, Test Accuracy: 0.49025973677635193, Precision: 0.4769230782985687, Recall: 0.20129869878292084\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "F1 Score: 0.2831050228310502\n",
            "Confusion Matrix:\n",
            "[[120  34]\n",
            " [123  31]]\n",
            "Training Results - Loss: 0.7253627777099609, Accuracy: 0.49025973677635193, Precision: 0.4769230782985687, Recall: 0.20129869878292084, F1 Score: 0.2831050228310502\n",
            "Test Loss: 0.7219962477684021, Test Accuracy: 0.5657894611358643, Precision: 0.6666666865348816, Recall: 0.2631579041481018\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "F1 Score: 0.3773584905660377\n",
            "Confusion Matrix:\n",
            "[[33  5]\n",
            " [28 10]]\n",
            "Validation Results - Loss: 0.7219962477684021, Accuracy: 0.5657894611358643, Precision: 0.6666666865348816, Recall: 0.2631579041481018, F1 Score: 0.3773584905660377\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def main():\n",
        "    global classifier\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}