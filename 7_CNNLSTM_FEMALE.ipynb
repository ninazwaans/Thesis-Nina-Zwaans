{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the LSTM implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my LSTM analysis."
      ],
      "metadata": {
        "id": "EjCCIQuw1md6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kj8lCByp9dFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036cd8c9-d5dd-43a8-ae43-f8e8e12d8d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "outputs": [],
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nB1g1ok5-QKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47471552-0c12-43be-a756-aba0e99f3778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 26, 4975)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "outputs": [],
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ba09ca-dc02-48e6-d3e2-28d6005e31c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ],
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)"
      ],
      "metadata": {
        "id": "4yOz0jBErINx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99885a3c-612e-4199-8468-e5ccbf3c3c18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "mhbmIqENrIWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a69d46-7147-48a2-9fb9-4094c35bfb32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 52, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = ec_eeg_labels"
      ],
      "metadata": {
        "id": "0xTKQqAMrNHf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD participants: {mdd_count}\")\n",
        "print(f\"Number of Healthy participants: {healthy_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o2e6442_rix",
        "outputId": "069fa76d-e4dc-40c2-e18d-e20219b27f2e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD participants: 3780\n",
            "Number of Healthy participants: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting data for female participants"
      ],
      "metadata": {
        "id": "VMj3gbuquMBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the participants data\n",
        "df_participants = pd.read_pickle('/content/drive/MyDrive/TD-BRAIN/TDBRAIN_participants_V2_data/df_participants.pkl')\n",
        "\n",
        "# Prepare lists to hold the filtered data and labels\n",
        "eeg_data_female = []\n",
        "eeg_label_female = []\n",
        "\n",
        "# Loop over each label in your existing eeg_labels list\n",
        "for i, labels in enumerate(eeg_labels):\n",
        "    sample_id = labels[0]\n",
        "    index = df_participants.loc[df_participants['participants_ID'] == sample_id].index\n",
        "\n",
        "    if not index.empty:  # Check if the index is not empty\n",
        "        participant_gender = df_participants.loc[index, 'gender'].values[0]\n",
        "        participant_condition = labels[1]  # Assuming the condition (MDD/HEALTHY) is stored in labels[1]\n",
        "\n",
        "        # Check if participant is female and has the condition \"Healthy\" or \"MDD\"\n",
        "        if participant_gender == 1 and (participant_condition == \"HEALTHY\" or participant_condition == \"MDD\"):\n",
        "            eeg_data_female.append(eeg_data[i])\n",
        "            eeg_label_female.append(labels)\n",
        "\n",
        "# Convert lists to NumPy arrays for further processing\n",
        "eeg_data_female = np.array(eeg_data_female)\n",
        "eeg_label_female = np.array(eeg_label_female)\n",
        "\n",
        "# Output the shape of the arrays to verify the results\n",
        "print(f\"Shape of female EEG data: {eeg_data_female.shape}\")\n",
        "print(f\"Shape of female EEG labels: {eeg_label_female.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AO_353PuuLbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c3ab4f-bf2b-413f-d9e6-cbdf45a77790"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of female EEG data: (1932, 52, 4975)\n",
            "Shape of female EEG labels: (1932, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "healthy_count_female, mdd_count_female = 0, 0\n",
        "for sample in eeg_label_female:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count_female += 1\n",
        "  else:\n",
        "      healthy_count_female += 1\n",
        "\n",
        "print(f\"Number of MDD female participants: {mdd_count_female}\")\n",
        "print(f\"Number of Healthy female participants: {healthy_count_female}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LmB6cG4_tyz",
        "outputId": "bcf8de9d-fc64-4fa8-fed5-03fa2ccd6777"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD female participants: 1740\n",
            "Number of Healthy female participants: 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0568a137-2eab-4b27-80f0-2f961b05c306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered eeg_label_female: 1920\n",
            "Length of filtered eeg_data_female: 1920\n",
            "1920\n",
            "160\n",
            "32\n",
            "(384, 52, 4975)\n"
          ]
        }
      ],
      "source": [
        "ll = eeg_label_female\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "eeg_label_female = [sample for i, sample in enumerate(eeg_label_female) if i not in indices_to_remove]\n",
        "eeg_data_female = [data for i, data in enumerate(eeg_data_female) if i not in indices_to_remove]\n",
        "print(\"Length of filtered eeg_label_female:\", len(eeg_label_female))\n",
        "print(\"Length of filtered eeg_data_female:\", len(eeg_data_female))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = eeg_label_female\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 16\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(eeg_label_female):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data_female[i])\n",
        "    y_train.append(eeg_label_female[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(52, 4975), lstm_units=32):\n",
        "        self.input_shape = input_shape\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=self.input_shape, kernel_regularizer=l2(0.001)))\n",
        "        model.add(Conv1D(filters=64, kernel_size=4, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(units=32, kernel_regularizer=l2(0.001)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=30, batch_size=16):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, callbacks=[early_stopping], verbose=0)\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        y_pred = self.model.predict(X_test, verbose=0)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X, verbose=0)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    overall_train_metrics = []\n",
        "    overall_val_metrics = []\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "        overall_train_metrics.append(train_metrics)\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        overall_val_metrics.append(val_metrics)\n",
        "        print()\n",
        "\n",
        "    # Calculate and print overall metrics\n",
        "    def calculate_overall_metrics(metrics_list):\n",
        "        avg_metrics = {}\n",
        "        for key in metrics_list[0].keys():\n",
        "            avg_metrics[key] = np.mean([metrics[key] for metrics in metrics_list], axis=0)\n",
        "        return avg_metrics\n",
        "\n",
        "    overall_train_metrics = calculate_overall_metrics(overall_train_metrics)\n",
        "    overall_val_metrics = calculate_overall_metrics(overall_val_metrics)\n",
        "\n",
        "    print(\"Overall Training Metrics:\")\n",
        "    print(overall_train_metrics)\n",
        "    print(\"\\nOverall Validation Metrics:\")\n",
        "    print(overall_val_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "xUXq0i0IqBgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17e3f93-f825-4909-c9b2-b7d617a712f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Training Results - Loss: 0.863817036151886, Accuracy: 0.7035830616950989, Precision: 0.6597937941551208, Recall: 0.8366013169288635, F1 Score: 0.7377521613832854\n",
            "Validation Results - Loss: 0.9418507218360901, Accuracy: 0.5974025726318359, Precision: 0.5769230723381042, Recall: 0.7692307829856873, F1 Score: 0.6593406593406593\n",
            "\n",
            "Fold 2:\n",
            "Training Results - Loss: 0.8576274514198303, Accuracy: 0.7100977301597595, Precision: 0.6927710771560669, Recall: 0.7516340017318726, F1 Score: 0.7210031347962382\n",
            "Validation Results - Loss: 0.8677336573600769, Accuracy: 0.7532467246055603, Precision: 0.717391312122345, Recall: 0.8461538553237915, F1 Score: 0.776470588235294\n",
            "\n",
            "Fold 3:\n",
            "Training Results - Loss: 0.8445729613304138, Accuracy: 0.7263843417167664, Precision: 0.6785714030265808, Recall: 0.8636363744735718, F1 Score: 0.76\n",
            "Validation Results - Loss: 0.8256698846817017, Accuracy: 0.7792207598686218, Precision: 0.7692307829856873, Recall: 0.7894737124443054, F1 Score: 0.7792207792207793\n",
            "\n",
            "Fold 4:\n",
            "Training Results - Loss: 0.7893283367156982, Accuracy: 0.7850162982940674, Precision: 0.7558139562606812, Recall: 0.8441558480262756, F1 Score: 0.7975460122699386\n",
            "Validation Results - Loss: 0.8249187469482422, Accuracy: 0.7532467246055603, Precision: 0.7111111283302307, Recall: 0.8421052694320679, F1 Score: 0.7710843373493975\n",
            "\n",
            "Fold 5:\n",
            "Training Results - Loss: 0.6965031623840332, Accuracy: 0.8636363744735718, Precision: 0.8888888955116272, Recall: 0.8311688303947449, F1 Score: 0.8590604026845637\n",
            "Validation Results - Loss: 0.71458500623703, Accuracy: 0.8157894611358643, Precision: 0.875, Recall: 0.7368420958518982, F1 Score: 0.7999999999999999\n",
            "\n",
            "Overall Training Metrics:\n",
            "{'loss': 0.8103697896003723, 'accuracy': 0.7577435612678528, 'precision': 0.7351678252220154, 'recall': 0.8254392743110657, 'f1_score': 0.7750723422268051, 'confusion_matrix': array([[106. ,  47.6],\n",
            "       [ 26.8, 126.8]])}\n",
            "\n",
            "Overall Validation Metrics:\n",
            "{'loss': 0.8349516034126282, 'accuracy': 0.7397812485694886, 'precision': 0.7299312591552735, 'recall': 0.7967611432075501, 'f1_score': 0.757223272829226, 'confusion_matrix': array([[26.2, 12.2],\n",
            "       [ 7.8, 30.6]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sajSL6DZTOZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}