{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I utilized the CNN implementation specifically tailored for EEG data from the following GitHub repository: https://github.com/theyou21/BigProject. This resource provided invaluable support for my CNN analysis."
      ],
      "metadata": {
        "id": "T_-Wzz-o2olK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8lCByp9dFa",
        "outputId": "94918189-5ae2-41bd-dfab-f14a07821260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "OSo-YwnR-aF2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ec_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_data_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_data = np.load(os.path.join(ec_data_dir, \"normalized_epoch_eeg_data.npy\"))\n",
        "eo_eeg_data = np.load(os.path.join(eo_data_dir, \"normalized_epoch_eeg_data.npy\"))"
      ],
      "metadata": {
        "id": "Mso-NzZ19uVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ec_eeg_data.shape)\n",
        "print(eo_eeg_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB1g1ok5-QKw",
        "outputId": "cf1e404d-d6b7-4531-8872-0a3e18042abd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 1, 26, 4975)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ec_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EC_26\"\n",
        "eo_labels_dir = \"/content/drive/MyDrive/TD-BRAIN/training_data/data/EO_26\"\n",
        "ec_eeg_labels = np.load(os.path.join(ec_labels_dir, \"labels_data.npy\"))\n",
        "eo_eeg_labels = np.load(os.path.join(eo_labels_dir, \"labels_data.npy\"))"
      ],
      "metadata": {
        "id": "aNA3Bh_u-jvy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ec_eeg_labels.shape)\n",
        "print(eo_eeg_labels.shape)"
      ],
      "metadata": {
        "id": "GjUzGyL7_Axu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce4b0c4-587f-45b9-9558-1465190054b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4356, 2)\n",
            "(4344, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in ec_eeg_labels:\n",
        "  sample_id = label[0]\n",
        "  if sample_id not in eo_eeg_labels[:, 0]:\n",
        "        index_to_remove = np.where(ec_eeg_labels[:, 0] == sample_id)[0]\n",
        "        ec_eeg_labels = np.delete(ec_eeg_labels, index_to_remove, axis=0)\n",
        "        ec_eeg_data = np.delete(ec_eeg_data, index_to_remove, axis=0)\n",
        "print(ec_eeg_labels.shape)\n",
        "print(ec_eeg_data.shape)\n",
        "\n",
        "eeg_data = np.concatenate((ec_eeg_data[:, 0], eo_eeg_data[:, 0]), axis=1)\n",
        "eeg_data.shape"
      ],
      "metadata": {
        "id": "5YrMjz4hnTVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de00923-1177-4a0b-c655-e00b4cb57f1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4344, 2)\n",
            "(4344, 1, 26, 4975)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 52, 4975)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_labels = eo_eeg_labels"
      ],
      "metadata": {
        "id": "_aa-u2qUnYkW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_count, mdd_count = 0, 0\n",
        "for sample in eeg_labels:\n",
        "  if sample[1] == \"MDD\":\n",
        "      mdd_count += 1\n",
        "  else:\n",
        "      healthy_count += 1\n",
        "\n",
        "print(f\"Number of MDD patient: {mdd_count}\")\n",
        "print(f\"Number of Healthy patient: {healthy_count}\")"
      ],
      "metadata": {
        "id": "_uu4_RU-iPuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b75323-9d06-4f43-d76c-816c37ec6c78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD patient: 3780\n",
            "Number of Healthy patient: 564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "VU0Kf2SFYNT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "b2X4KAfWcAVk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll = ec_eeg_labels\n",
        "encountered_sample_ids = {}\n",
        "sample_ids_with_more_than_12_entries = []\n",
        "\n",
        "for index, sample_id in enumerate(ll):\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    count = encountered_sample_ids.get(sample_id_tuple, 0)\n",
        "    count += 1\n",
        "    encountered_sample_ids[sample_id_tuple] = count\n",
        "    if count > 12:\n",
        "        sample_ids_with_more_than_12_entries.append((sample_id_tuple, index))\n",
        "\n",
        "indices_to_remove = [index for _, index in sample_ids_with_more_than_12_entries]\n",
        "ec_eeg_labels = [sample for i, sample in enumerate(ec_eeg_labels) if i not in indices_to_remove]\n",
        "eeg_data = [data for i, data in enumerate(eeg_data) if i not in indices_to_remove]\n",
        "print(\"Length of filtered ec_eeg_labels:\", len(ec_eeg_labels))\n",
        "print(\"Length of filtered eeg_data:\", len(eeg_data))\n",
        "\n",
        "\n",
        "###### Undersampling and preparing training data ########\n",
        "ll = ec_eeg_labels\n",
        "unique_sample_id = []\n",
        "encountered_sample_ids = set()\n",
        "print(len(ll))\n",
        "for sample_id in ll:\n",
        "    sample_id_tuple = tuple(sample_id)\n",
        "    if sample_id_tuple not in encountered_sample_ids:\n",
        "        unique_sample_id.append(sample_id)\n",
        "        encountered_sample_ids.add(sample_id_tuple)\n",
        "print(len(unique_sample_id))\n",
        "\n",
        "num_samples_minority = 47\n",
        "indices_maj = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"MDD\"]\n",
        "indices_min = [index for index, sample in enumerate(unique_sample_id) if sample[1] == \"HEALTHY\"]\n",
        "undersampled = np.random.choice(indices_maj, num_samples_minority, replace=False)\n",
        "\n",
        "balanced_data_indices = np.concatenate([indices_min, undersampled])\n",
        "# print(unique_sample_id)\n",
        "balanced_unique_sample_id = [unique_sample_id[i] for i in balanced_data_indices]\n",
        "\n",
        "# Extract all unique sample IDs from train_unique_sample_id\n",
        "unique_sample_ids = [sample_id[0] for sample_id in balanced_unique_sample_id]\n",
        "print(len(unique_sample_ids))\n",
        "# Extract all indices from eeg_labels for sample IDs in train_unique_sample_id\n",
        "indices = []\n",
        "for i, sample_id in enumerate(ec_eeg_labels):\n",
        "  # print(sample_id[0])\n",
        "  if sample_id[0] in unique_sample_ids:\n",
        "        indices.append(i)\n",
        "\n",
        "# Convert indices to a NumPy array\n",
        "indices = np.array(indices)\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in indices:\n",
        "    X_train.append(eeg_data[i])\n",
        "    y_train.append(eeg_labels[i])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# Shuffle together with their indices\n",
        "permutation = np.random.permutation(len(X_train))\n",
        "X_train = X_train[permutation]\n",
        "y_train = y_train[permutation]\n",
        "\n",
        "print(X_train.shape)\n",
        "# print(y_train)\n",
        "\n",
        "sample_ids = []\n",
        "for sample in y_train:\n",
        "  sample_ids.append(sample[0])\n",
        "sample_ids = np.array(sample_ids)\n",
        "l = np.array([1 if label[1] == \"MDD\" else 0 for label in y_train])"
      ],
      "metadata": {
        "id": "WyCSl6BScBEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fae60e-8b70-42cb-b10d-53e251fb99fa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of filtered ec_eeg_labels: 4248\n",
            "Length of filtered eeg_data: 4248\n",
            "4248\n",
            "354\n",
            "94\n",
            "(1128, 52, 4975)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of MDD patients:\", len(undersampled))\n",
        "print(\"Number of Healthy patients:\", len(indices_min))\n"
      ],
      "metadata": {
        "id": "ZZahRy9EHi-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aaa7c9c-ee85-4ba6-fe7d-652e9c8ac988"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MDD patients: 47\n",
            "Number of Healthy patients: 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class EEGClassifier:\n",
        "    def __init__(self, input_shape=(52, 4975), lstm_units=32):\n",
        "        self.input_shape = input_shape\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv1D(filters=32, kernel_size=4, activation='relu', input_shape=self.input_shape))\n",
        "        model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(LSTM(units=32))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(units=64, activation='relu'))\n",
        "        model.add(Dense(units=1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0005), metrics=['accuracy', Precision(), Recall()])\n",
        "        return model\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=30, batch_size=32):\n",
        "        # Calculate class weights\n",
        "        class_weights = {0: 1, 1: 1}  # Initialize with equal weights\n",
        "        num_minority = np.sum(y_train == 0)\n",
        "        num_majority = np.sum(y_train == 1)\n",
        "        total_samples = len(y_train)\n",
        "        class_weights[0] = (1 / num_minority) * (total_samples / 2.0)\n",
        "        class_weights[1] = (1 / num_majority) * (total_samples / 2.0)\n",
        "\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), class_weight=class_weights, verbose=0)\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        loss, accuracy, precision, recall = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "        y_pred = self.model.predict(X_test, verbose=0)\n",
        "        y_pred_classes = np.round(y_pred)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "        cm = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "        evaluation_metrics = {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "        return evaluation_metrics\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X, verbose=0)\n",
        "\n",
        "    def plot_loss(self, history):\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    classifier = EEGClassifier()\n",
        "\n",
        "    num_splits = 5\n",
        "    cv = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    overall_train_metrics = []\n",
        "    overall_val_metrics = []\n",
        "\n",
        "    for fold_idx, (train_index, val_index) in enumerate(cv.split(X_train, l), 1):\n",
        "        print(f\"Fold {fold_idx}:\")\n",
        "\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = l[train_index], l[val_index]\n",
        "\n",
        "        history = classifier.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "\n",
        "        # Evaluate on training set after training\n",
        "        train_metrics = classifier.evaluate(X_train_fold, y_train_fold)\n",
        "        print(f'Training Results - Loss: {train_metrics[\"loss\"]}, Accuracy: {train_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {train_metrics[\"precision\"]}, Recall: {train_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {train_metrics[\"f1_score\"]}')\n",
        "        overall_train_metrics.append(train_metrics)\n",
        "\n",
        "        # Evaluate on the validation set after training\n",
        "        val_metrics = classifier.evaluate(X_val_fold, y_val_fold)\n",
        "        print(f'Validation Results - Loss: {val_metrics[\"loss\"]}, Accuracy: {val_metrics[\"accuracy\"]}, '\n",
        "              f'Precision: {val_metrics[\"precision\"]}, Recall: {val_metrics[\"recall\"]}, '\n",
        "              f'F1 Score: {val_metrics[\"f1_score\"]}')\n",
        "        overall_val_metrics.append(val_metrics)\n",
        "        print()\n",
        "\n",
        "    # Calculate and print overall metrics\n",
        "    def calculate_overall_metrics(metrics_list):\n",
        "        avg_metrics = {}\n",
        "        for key in metrics_list[0].keys():\n",
        "            avg_metrics[key] = np.mean([metrics[key] for metrics in metrics_list], axis=0)\n",
        "        return avg_metrics\n",
        "\n",
        "    overall_train_metrics = calculate_overall_metrics(overall_train_metrics)\n",
        "    overall_val_metrics = calculate_overall_metrics(overall_val_metrics)\n",
        "\n",
        "    print(\"Overall Training Metrics:\")\n",
        "    print(overall_train_metrics)\n",
        "    print(\"\\nOverall Validation Metrics:\")\n",
        "    print(overall_val_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uXbpuk_K8W7",
        "outputId": "3732d1a1-6367-4570-821c-fa0dd24d3fa8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "Training Results - Loss: 0.18091796338558197, Accuracy: 0.932372510433197, Precision: 0.9712746739387512, Recall: 0.9232081770896912, F1 Score: 0.9466316710411199\n",
            "Validation Results - Loss: 1.420715570449829, Accuracy: 0.5486725568771362, Precision: 0.6746031641960144, Recall: 0.5821917653083801, F1 Score: 0.625\n",
            "\n",
            "Fold 2:\n",
            "Training Results - Loss: 0.03769639879465103, Accuracy: 0.9866962432861328, Precision: 0.9931153059005737, Recall: 0.9863247871398926, F1 Score: 0.9897084048027444\n",
            "Validation Results - Loss: 0.7621968984603882, Accuracy: 0.7964601516723633, Precision: 0.885496199131012, Recall: 0.7891156673431396, F1 Score: 0.8345323741007193\n",
            "\n",
            "Fold 3:\n",
            "Training Results - Loss: 0.010557527653872967, Accuracy: 0.9966740608215332, Precision: 0.9982876777648926, Recall: 0.9965811967849731, F1 Score: 0.9974337040205304\n",
            "Validation Results - Loss: 0.3462229371070862, Accuracy: 0.9159291982650757, Precision: 0.9444444179534912, Recall: 0.9251700639724731, F1 Score: 0.9347079037800687\n",
            "\n",
            "Fold 4:\n",
            "Training Results - Loss: 0.0032401124481111765, Accuracy: 0.998892605304718, Precision: 0.9982964396476746, Recall: 1.0, F1 Score: 0.9991474850809888\n",
            "Validation Results - Loss: 0.09284180402755737, Accuracy: 0.9733333587646484, Precision: 0.9794520735740662, Recall: 0.9794520735740662, F1 Score: 0.9794520547945206\n",
            "\n",
            "Fold 5:\n",
            "Training Results - Loss: 0.002505979035049677, Accuracy: 0.998892605304718, Precision: 1.0, Recall: 0.9982935190200806, F1 Score: 0.9991460290350128\n",
            "Validation Results - Loss: 0.1982201635837555, Accuracy: 0.9511111378669739, Precision: 0.9530201554298401, Recall: 0.9726027250289917, F1 Score: 0.9627118644067796\n",
            "\n",
            "Overall Training Metrics:\n",
            "{'loss': 0.046983596263453366, 'accuracy': 0.9827056050300598, 'precision': 0.9921948194503785, 'recall': 0.9808815360069275, 'f1_score': 0.9864134587960793, 'confusion_matrix': array([[312.4,   4.4],\n",
            "       [ 11.2, 574.4]])}\n",
            "\n",
            "Overall Validation Metrics:\n",
            "{'loss': 0.5640394747257232, 'accuracy': 0.8371012806892395, 'precision': 0.8874032020568847, 'recall': 0.8497064590454102, 'f1_score': 0.8672808394164176, 'confusion_matrix': array([[ 64.4,  14.8],\n",
            "       [ 22. , 124.4]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8yj1azsLZBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}